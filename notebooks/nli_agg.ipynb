{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d918323-c74d-4d47-b8e0-b586240b543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb97316b6f5b4ccda70229b1ef84a7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747fead4886246a692d4461dbd113c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3a970335a14ed0afb63dac9c7a6b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822beb1b872b4e9bb3f8339fb40bd36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a363ac59954241b4c00b2de686788a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11bd50d73954c84956400989d2a0bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder('cross-encoder/nli-deberta-v3-large', device='cuda:7')\n",
    "# model = CrossEncoder('cross-encoder/nli-deberta-v3-base', device='cuda:7')\n",
    "# model = CrossEncoder('cross-encoder/nli-deberta-v3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8e3d06-457b-4145-a44d-09d9cf7806b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Any, List\n",
    "\n",
    "def read_jsonl(path: Path):\n",
    "    with path.open(encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "data = read_jsonl(Path(\"../atomic_facts.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f4cb53-53d9-473b-be8d-2f776a5a1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_ce_score(pairs):\n",
    "    scores = model.predict(pairs)\n",
    "    label_names = ['contradiction', 'entailment', 'neutral']\n",
    "    predictions = []\n",
    "    for pred in scores:\n",
    "        predictions.append({name: round(float(pred), 2) for pred, name in zip(pred, label_names)})\n",
    "    return predictions\n",
    "\n",
    "def get_custom_scores(input):\n",
    "    pairs = list(itertools.combinations(input, r=2))\n",
    "    \n",
    "    formatted_pairs = [(pair[0], pair[1]) for pair in pairs]\n",
    "    scores_1 = get_ce_score(formatted_pairs)\n",
    "\n",
    "    formatted_pairs = [(pair[1], pair[0]) for pair in pairs]\n",
    "    scores_2 = get_ce_score(formatted_pairs)\n",
    "    return scores_1, scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dd3ef77-6f25-4ccb-abd5-ec7175acf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_agg(input, ent_w, cont_w, neutral_w):\n",
    "    ent = input['entailment']\n",
    "    cont = input['contradiction']\n",
    "    neutral = input['neutral']\n",
    "\n",
    "    weighted_sum = ent_w * ent + neutral_w * neutral + cont_w * cont\n",
    "    return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4901a6-cca3-400f-a93b-bbf96e29973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def aggregation(scores_1, scores_2, ent_w=1, cont_w=-1, neutral_w=0):\n",
    "    agg_1 = [weighted_agg(s, ent_w, cont_w, neutral_w) for s in scores_1]\n",
    "    agg_2 = [weighted_agg(s, ent_w, cont_w, neutral_w) for s in scores_2]\n",
    "\n",
    "    agg = np.array(agg_1 + agg_2)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(agg.reshape(-1, 1))\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    return np.min(centroids)\n",
    "\n",
    "    # abs_max = np.argmax(np.absolute(agg)) \n",
    "    # return agg[abs_max]\n",
    "\n",
    "    # return np.min(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff69322a-66a4-4f20-a827-e8e095624fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102/102 [00:20<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "normal_scores = []\n",
    "strange_scores = []\n",
    "\n",
    "for sample in tqdm(data):\n",
    "    normal_scores.append(get_custom_scores(sample['normal']))\n",
    "    strange_scores.append(get_custom_scores(sample['strange']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92a3ac3c-1c35-4d51-a2d5-a86ab8e78108",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = [0] * len(normal_scores) + [1] * len(strange_scores)\n",
    "scores = normal_scores + strange_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a78e72e4-8dc3-4ff0-9f4d-6fceff340c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_weights_on_test(test_scores, test_labels, ent_w, cont_w, neutral_w, thr=0):\n",
    "    agg_scores = []\n",
    "\n",
    "    for score in test_scores:\n",
    "        agg_scores.append(aggregation(*score, ent_w=ent_w, cont_w=cont_w, neutral_w=neutral_w))\n",
    "    \n",
    "    our_outputs = [el < thr for el in agg_scores]\n",
    "\n",
    "    return accuracy_score(test_labels, our_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0260a9f6-9364-4998-b389-6e872c603eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:14<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last fold acc=74.26% on thr=0.0 ent_w=1.75, cont_w=-0.25, neutral_w=0.0, test_acc=0.6911764705882353\n",
      "FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:14<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last fold acc=72.06% on thr=0.0 ent_w=1.75, cont_w=-0.25, neutral_w=0.0, test_acc=0.7352941176470589\n",
      "FOLD 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:15<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last fold acc=71.32% on thr=0.0 ent_w=1.75, cont_w=-0.25, neutral_w=0.0, test_acc=0.75\n",
      "Mean acc: 72.55\n",
      "std: 2.5\n",
      "var: 0.06\n",
      "accs: [0.6911764705882353, 0.7352941176470589, 0.75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "kf.get_n_splits(scores)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(scores)):\n",
    "    best_acc = 0\n",
    "    print(f\"FOLD {i}\")\n",
    "    train_scores = np.array(scores)[train_index]\n",
    "    train_labels = np.array(true_classes)[train_index]\n",
    "    test_scores = np.array(scores)[test_index]\n",
    "    test_labels = np.array(true_classes)[test_index]\n",
    "    \n",
    "    for ent_w in tqdm(np.arange(0, 2, 0.25)):\n",
    "        for cont_w in np.arange(-2, 0, 0.25):\n",
    "            # for neutral_w in np.arange(-0.25, 0.25, 0.25):\n",
    "                neutral_w = 0.0\n",
    "                if ent_w == 0 and cont_w == 0 and neutral_w == 0:\n",
    "                    continue\n",
    "                agg_scores = []\n",
    "\n",
    "                for score in train_scores:\n",
    "                    agg_scores.append(aggregation(*score, ent_w=ent_w, cont_w=cont_w, neutral_w=neutral_w))\n",
    "\n",
    "                thr = 0.0\n",
    "                our_outputs = [el < thr for el in agg_scores]\n",
    "                acc = accuracy_score(train_labels, our_outputs)\n",
    "        \n",
    "                if acc >= best_acc:\n",
    "                    test_acc = eval_weights_on_test(test_scores, test_labels, ent_w, cont_w, neutral_w, 0.0)\n",
    "                    best_acc = acc\n",
    "                    best_ent_w = ent_w\n",
    "                    best_cont_w = cont_w\n",
    "                    best_neutral_w = neutral_w\n",
    "    print(f\"last fold acc={round(best_acc * 100, 2)}% on {thr=} {ent_w=}, {cont_w=}, {neutral_w=}, {test_acc=}\")\n",
    "    fold_accuracies.append(test_acc)\n",
    "\n",
    "print(f\"Mean acc: {(np.mean(fold_accuracies) * 100).round(2)}\")\n",
    "print(f\"std: {(np.std(fold_accuracies) * 100).round(2)}\")\n",
    "print(f\"var: {(np.var(fold_accuracies) * 100).round(2)}\")\n",
    "print(f\"accs: {fold_accuracies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "058975c8-dbe7-4a99-81e7-edffafd5bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7254901960784313"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_weights_on_test(scores, true_classes, ent_w=1.75, cont_w=-2.0, neutral_w=0.0, thr=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
